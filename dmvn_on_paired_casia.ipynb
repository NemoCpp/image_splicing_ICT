{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This script evaluates the Deep Matching and Validation Network (DMVN) on the paired CASIA dataset\n",
    "\n",
    "Before you run this notebook, make sure\n",
    "    \n",
    "    - you have prepared the CASIA dataset as described in `data/README.md` \n",
    "    - you correctly set up your **Keras** enviroment with the Theano backend\n",
    "    - standard libraries **NumPy**, **IPython**, and **cv2**(v2.4.9) are available\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Load all required libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "ERROR (theano.sandbox.cuda): nvcc compiler not found on $PATH. Check your nvcc installation and try again.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np \n",
    "dmvn_root = os.getcwd()\n",
    "dmvn_lib = os.path.join( dmvn_root, 'lib', 'dmvn' )\n",
    "sys.path.insert( 0, dmvn_lib )\n",
    "from core import create_DMVN_model\n",
    "from utils import load_splicing_input_csv, get_unique_images_and_idxLUT, preprocess_images, filter_invalid_data, prepare_one_batch_input\n",
    "from utils import visualize_debug_dualmask, evaluate_fscore, evaluate_auc\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve\n",
    "np.set_printoptions(3,suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Set inputs and ouputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input paired CASIA dataset\n",
    "input_splicing_csv = os.path.join( dmvn_root, 'data', 'local_paired_CASIA_files.csv' ) \n",
    "assert os.path.isfile( input_splicing_csv ), \"ERROR: please prepare CASIA2 data as described in data/README.md\"\n",
    "\n",
    "# set output experiment directory\n",
    "expt_dir = os.path.join( dmvn_root, 'expt', 'test_on_paired_casia' )\n",
    "os.system( \"mkdir -p %s\" % expt_dir )\n",
    "visualization_dir = os.path.join( expt_dir, 'visualization_results')\n",
    "os.system( \"mkdir -p %s\" % visualization_dir)\n",
    "output_res_csv = os.path.join( expt_dir, 'dmvn_on_paired_casia.csv' )\n",
    "\n",
    "# set up decoding parameters\n",
    "batch_size = 16 # batch size in DMVN process\n",
    "visualization_level = -1 # if -1: suppress everything, 0: only print proba but no image, 1: only positive samples, 2: everything\n",
    "vis_mask_thresh = 0.5 # mask threshold, if negative then use grayscale mask instead of binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Prepare the paired CASIA2 data\n",
    "\n",
    "It is known that OpenCV has problems to load some gif and tif images in CASIA2. To overcome this problem, one may first convert these problematic images manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   5 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=10)]: Done  12 tasks      | elapsed:    2.5s\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=10)]: Done  41 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=10)]: Done  52 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=10)]: Done  65 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=10)]: Done  78 tasks      | elapsed:    6.2s\n",
      "[Parallel(n_jobs=10)]: Done  93 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=10)]: Done 108 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=10)]: Done 125 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=10)]: Done 142 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=10)]: Done 161 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    7.6s\n",
      "[Parallel(n_jobs=10)]: Done 201 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=10)]: Done 222 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=10)]: Done 245 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=10)]: Done 268 tasks      | elapsed:   12.4s\n",
      "[Parallel(n_jobs=10)]: Done 293 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=10)]: Done 318 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=10)]: Done 345 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=10)]: Done 372 tasks      | elapsed:   17.9s\n",
      "[Parallel(n_jobs=10)]: Done 401 tasks      | elapsed:   19.7s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=10)]: Done 461 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=10)]: Done 492 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=10)]: Done 525 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=10)]: Done 558 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=10)]: Done 593 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=10)]: Done 628 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=10)]: Done 665 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=10)]: Done 702 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=10)]: Done 741 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=10)]: Done 821 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=10)]: Done 862 tasks      | elapsed:   22.6s\n",
      "[Parallel(n_jobs=10)]: Done 905 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=10)]: Done 948 tasks      | elapsed:   22.9s\n",
      "[Parallel(n_jobs=10)]: Done 993 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=10)]: Done 1038 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=10)]: Done 1085 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=10)]: Done 1132 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=10)]: Done 1181 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=10)]: Done 1281 tasks      | elapsed:   29.4s\n",
      "[Parallel(n_jobs=10)]: Done 1332 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=10)]: Done 1385 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=10)]: Done 1438 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=10)]: Done 1493 tasks      | elapsed:   39.3s\n",
      "[Parallel(n_jobs=10)]: Done 1548 tasks      | elapsed:   42.5s\n",
      "[Parallel(n_jobs=10)]: Done 1605 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=10)]: Done 1662 tasks      | elapsed:   48.0s\n",
      "[Parallel(n_jobs=10)]: Done 1721 tasks      | elapsed:   51.4s\n",
      "[Parallel(n_jobs=10)]: Done 1780 tasks      | elapsed:   53.0s\n",
      "[Parallel(n_jobs=10)]: Done 1841 tasks      | elapsed:   57.1s\n",
      "[Parallel(n_jobs=10)]: Done 1902 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=10)]: Done 1965 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=10)]: Done 2028 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=10)]: Done 2093 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=10)]: Done 2158 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2225 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2292 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2361 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2430 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2501 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2572 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2645 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2718 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 2793 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=10)]: Done 2868 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 2945 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 3022 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 3101 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 3180 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 3261 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 3342 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 3425 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 3508 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 3593 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=10)]: Done 3678 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 3765 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 3852 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 3941 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 4030 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 4121 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=10)]: Done 4212 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done 4305 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=10)]: Done 4398 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=10)]: Done 4493 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=10)]: Done 4588 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=10)]: Done 4685 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=10)]: Done 4782 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=10)]: Done 4881 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=10)]: Done 4980 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5081 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5182 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5285 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5388 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5493 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5598 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=10)]: Done 5705 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done 5812 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done 5921 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done 6030 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=10)]: Done 6141 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=10)]: Done 6252 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=10)]: Done 6365 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=10)]: Done 6478 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=10)]: Done 6593 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=10)]: Done 6708 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=10)]: Done 6825 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=10)]: Done 6942 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=10)]: Done 7061 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=10)]: Done 7180 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=10)]: Done 7301 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=10)]: Done 7422 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=10)]: Done 7545 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=10)]: Done 7663 out of 7663 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: meet #invalid_image_samples = 0\n"
     ]
    }
   ],
   "source": [
    "# load input pairs and groundtruth labels\n",
    "splicing_img_pair_list, label_list = load_splicing_input_csv( input_splicing_csv )\n",
    "# reduce image pairs to unique images\n",
    "splicing_idx_pair_list, unique_image_list = get_unique_images_and_idxLUT( splicing_img_pair_list )\n",
    "# load unique images and convert to tensors\n",
    "sample_tensor_list = preprocess_images( unique_image_list, n_jobs = 8, verbose = 10 )\n",
    "# filter invalid samples\n",
    "valid_idx_pair_list, valid_image_pair_list = filter_invalid_data( sample_tensor_list, splicing_idx_pair_list, splicing_img_pair_list )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. DMVN prediction over all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "INFO: create CNN Feature Extractor\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block1_conv1 (C (None, 64, 256, 256)  1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block1_conv2 (C (None, 64, 256, 256)  36928       vgg16_cnn_featex-block1_conv1[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block1_pool (Ma (None, 64, 128, 128)  0           vgg16_cnn_featex-block1_conv2[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block2_conv1 (C (None, 128, 128, 128) 73856       vgg16_cnn_featex-block1_pool[0][0\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block2_conv2 (C (None, 128, 128, 128) 147584      vgg16_cnn_featex-block2_conv1[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block2_pool (Ma (None, 128, 64, 64)   0           vgg16_cnn_featex-block2_conv2[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block3_conv1 (C (None, 256, 64, 64)   295168      vgg16_cnn_featex-block2_pool[0][0\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block3_conv2 (C (None, 256, 64, 64)   590080      vgg16_cnn_featex-block3_conv1[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block3_conv3 (C (None, 256, 64, 64)   590080      vgg16_cnn_featex-block3_conv2[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block3_pool (Ma (None, 256, 32, 32)   0           vgg16_cnn_featex-block3_conv3[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block4_conv1 (C (None, 512, 32, 32)   1180160     vgg16_cnn_featex-block3_pool[0][0\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block4_conv2 (C (None, 512, 32, 32)   2359808     vgg16_cnn_featex-block4_conv1[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block4_conv3 (C (None, 512, 32, 32)   2359808     vgg16_cnn_featex-block4_conv2[0][\n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex-block4_pool (Ma (None, 512, 16, 16)   0           vgg16_cnn_featex-block4_conv3[0][\n",
      "====================================================================================================\n",
      "Total params: 7,635,264\n",
      "Trainable params: 7,635,264\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "INFO: create Deep Feature Correlation module\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "feat_x (InputLayer)              (None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "feat_y (InputLayer)              (None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "match_xy (TensorwiseCorrelation) (None, 256, 16, 16)   0           feat_x[0][0]                     \n",
      "                                                                   feat_y[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "corr(x,y) (InputLayer)           (None, 256, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "match_pool_p1 (Lambda)           (None, 1, 16, 16)     0           corr(x,y)[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "match_pool_p2 (Lambda)           (None, 1, 16, 16)     0           corr(x,y)[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "match_pool_p3 (Lambda)           (None, 6, 16, 16)     0           corr(x,y)[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "match_pool_concat (Merge)        (None, 8, 16, 16)     0           match_pool_p1[0][0]              \n",
      "                                                                   match_pool_p2[0][0]              \n",
      "                                                                   match_pool_p3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "pool_inceptor (Model)            multiple              36032       match_pool_concat[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "match_inception_corr_inceptor_co (None, 32, 16, 16)    36896       pool_inceptor[1][0]              \n",
      "====================================================================================================\n",
      "Total params: 72,928\n",
      "Trainable params: 72,928\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "INFO: create Mask DeConvolution module\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "x_res_x (InputLayer)             (None, 32, 16, 16)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "y_res_x (InputLayer)             (None, 32, 16, 16)    0                                            \n",
      "____________________________________________________________________________________________________\n",
      "merged_response (Merge)          (None, 64, 16, 16)    0           x_res_x[0][0]                    \n",
      "                                                                   y_res_x[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "mask_map@32 (UpSampling2D)       (None, 64, 32, 32)    0           merged_response[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "mask_inceptor@32 (Model)         multiple              8972        mask_map@32[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "mask_map@64 (UpSampling2D)       (None, 12, 64, 64)    0           mask_inceptor@32[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mask_inceptor@64 (Model)         multiple              1269        mask_map@64[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "mask_map@128 (UpSampling2D)      (None, 9, 128, 128)   0           mask_inceptor@64[1][0]           \n",
      "____________________________________________________________________________________________________\n",
      "mask_inceptor@128 (Model)        multiple              636         mask_map@128[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "mask_map@256 (UpSampling2D)      (None, 6, 256, 256)   0           mask_inceptor@128[1][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mask_inceptor@256 (Model)        multiple              213         mask_map@256[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "mask_inceptorMask (Model)        multiple              588         mask_inceptor@256[1][0]          \n",
      "____________________________________________________________________________________________________\n",
      "mask (Convolution2D)             (None, 1, 256, 256)   4           mask_inceptorMask[1][0]          \n",
      "====================================================================================================\n",
      "Total params: 11,682\n",
      "Trainable params: 11,682\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "INFO: create Visual Consistency Validator\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "visual_validator_world_mask (Inp (None, 1, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "visual_validator_probe_mask (Inp (None, 1, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "visual_validator_world_vgg (Inpu (None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "pool_max (Model)                 (None, 1, 16, 16)     0           visual_validator_world_mask[0][0]\n",
      "                                                                   visual_validator_probe_mask[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "visual_validator_probe_vgg (Inpu (None, 512, 16, 16)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "visual_attention (Model)         (None, 512, 16, 16)   0           visual_validator_world_vgg[0][0] \n",
      "                                                                   pool_max[1][0]                   \n",
      "                                                                   visual_validator_probe_vgg[0][0] \n",
      "                                                                   pool_max[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "proba_featex (Model)             (None, 512)           2683008     visual_attention[1][0]           \n",
      "                                                                   visual_attention[2][0]           \n",
      "____________________________________________________________________________________________________\n",
      "attention_concat (Merge)         (None, 2, 16, 16)     0           pool_max[1][0]                   \n",
      "                                                                   pool_max[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "siamese (Merge)                  (None, 512)           0           proba_featex[1][0]               \n",
      "                                                                   proba_featex[2][0]               \n",
      "____________________________________________________________________________________________________\n",
      "global_pool (GlobalAveragePoolin (None, 2)             0           attention_concat[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropOut@0.5 (Dropout)            multiple              0           siamese[0][0]                    \n",
      "                                                                   siamese_f1[0][0]                 \n",
      "                                                                   siamese_f2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "avg_pool_dense (Dense)           (None, 8)             24          global_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "proba_feat_concat (Merge)        (None, 520)           0           dropOut@0.5[0][0]                \n",
      "                                                                   avg_pool_dense[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "siamese_f1 (Dense)               (None, 128)           66688       proba_feat_concat[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "siamese_f2 (Dense)               (None, 32)            4128        dropOut@0.5[1][0]                \n",
      "====================================================================================================\n",
      "Total params: 2,753,848\n",
      "Trainable params: 2,753,848\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "INFO: create end-to-end DMVN model\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "probe (InputLayer)               (None, 3, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "world (InputLayer)               (None, 3, 256, 256)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "vgg16_cnn_featex (Model)         (None, 512, 16, 16)   7635264     world[0][0]                      \n",
      "                                                                   probe[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_feat_corr (Model)          (None, 256, 16, 16)   0           vgg16_cnn_featex[1][0]           \n",
      "                                                                   vgg16_cnn_featex[2][0]           \n",
      "                                                                   vgg16_cnn_featex[2][0]           \n",
      "                                                                   vgg16_cnn_featex[1][0]           \n",
      "                                                                   vgg16_cnn_featex[1][0]           \n",
      "                                                                   vgg16_cnn_featex[1][0]           \n",
      "                                                                   vgg16_cnn_featex[2][0]           \n",
      "                                                                   vgg16_cnn_featex[2][0]           \n",
      "____________________________________________________________________________________________________\n",
      "match_inception_corr (Model)     (None, 32, 16, 16)    72928       dense_feat_corr[1][0]            \n",
      "                                                                   dense_feat_corr[2][0]            \n",
      "                                                                   dense_feat_corr[3][0]            \n",
      "                                                                   dense_feat_corr[4][0]            \n",
      "____________________________________________________________________________________________________\n",
      "mask_predictor (Model)           (None, 1, 256, 256)   11682       match_inception_corr[2][0]       \n",
      "                                                                   match_inception_corr[3][0]       \n",
      "                                                                   match_inception_corr[1][0]       \n",
      "                                                                   match_inception_corr[4][0]       \n",
      "____________________________________________________________________________________________________\n",
      "visual_validator (Model)         (None, 32)            2753848     mask_predictor[1][0]             \n",
      "                                                                   mask_predictor[2][0]             \n",
      "                                                                   vgg16_cnn_featex[1][0]           \n",
      "                                                                   vgg16_cnn_featex[2][0]           \n",
      "____________________________________________________________________________________________________\n",
      "pred_masks (Merge)               (None, 2, 256, 256)   0           mask_predictor[1][0]             \n",
      "                                                                   mask_predictor[2][0]             \n",
      "____________________________________________________________________________________________________\n",
      "pred_probs (Dense)               (None, 2)             66          visual_validator[1][0]           \n",
      "====================================================================================================\n",
      "Total params: 10,473,788\n",
      "Trainable params: 10,473,788\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n",
      "INFO: successfully load pretrained weights from /nas/medifor/yue_wu/release/Deep-Matching-Validation-Network/lib/dmvn/../../model/dmvn_end_to_end.h5\n",
      "////////////////////////////////////////////////////////////////////////////////////////////////////\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_weight' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-245614614d89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load pretrained model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdmvn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_DMVN_model\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m256\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdmvn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmodel_weight\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnb_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;31m#len( valid_idx_pair_list )\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_weight' is not defined"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "dmvn_model = create_DMVN_model( ( 3, 256, 256 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: done 16 samples out of 8642\n",
      "INFO: done 32 samples out of 8642\n",
      "INFO: done 48 samples out of 8642\n",
      "INFO: done 64 samples out of 8642\n",
      "INFO: done 80 samples out of 8642\n",
      "INFO: done 96 samples out of 8642\n",
      "INFO: done 112 samples out of 8642\n",
      "INFO: done 128 samples out of 8642\n",
      "INFO: done 144 samples out of 8642\n",
      "INFO: done 160 samples out of 8642\n",
      "INFO: done 176 samples out of 8642\n",
      "INFO: done 192 samples out of 8642\n",
      "INFO: done 208 samples out of 8642\n",
      "INFO: done 224 samples out of 8642\n",
      "INFO: done 240 samples out of 8642\n",
      "INFO: done 256 samples out of 8642\n",
      "INFO: done 272 samples out of 8642\n",
      "INFO: done 288 samples out of 8642\n",
      "INFO: done 304 samples out of 8642\n",
      "INFO: done 320 samples out of 8642\n",
      "INFO: done 336 samples out of 8642\n",
      "INFO: done 352 samples out of 8642\n",
      "INFO: done 368 samples out of 8642\n",
      "INFO: done 384 samples out of 8642\n",
      "INFO: done 400 samples out of 8642\n",
      "INFO: done 416 samples out of 8642\n",
      "INFO: done 432 samples out of 8642\n",
      "INFO: done 448 samples out of 8642\n",
      "INFO: done 464 samples out of 8642\n",
      "INFO: done 480 samples out of 8642\n",
      "INFO: done 496 samples out of 8642\n",
      "INFO: done 512 samples out of 8642\n",
      "INFO: done 528 samples out of 8642\n",
      "INFO: done 544 samples out of 8642\n",
      "INFO: done 560 samples out of 8642\n",
      "INFO: done 576 samples out of 8642\n",
      "INFO: done 592 samples out of 8642\n",
      "INFO: done 608 samples out of 8642\n",
      "INFO: done 624 samples out of 8642\n",
      "INFO: done 640 samples out of 8642\n",
      "INFO: done 656 samples out of 8642\n",
      "INFO: done 672 samples out of 8642\n",
      "INFO: done 688 samples out of 8642\n",
      "INFO: done 704 samples out of 8642\n",
      "INFO: done 720 samples out of 8642\n",
      "INFO: done 736 samples out of 8642\n",
      "INFO: done 752 samples out of 8642\n",
      "INFO: done 768 samples out of 8642\n",
      "INFO: done 784 samples out of 8642\n",
      "INFO: done 800 samples out of 8642\n",
      "INFO: done 816 samples out of 8642\n",
      "INFO: done 832 samples out of 8642\n",
      "INFO: done 848 samples out of 8642\n",
      "INFO: done 864 samples out of 8642\n",
      "INFO: done 880 samples out of 8642\n",
      "INFO: done 896 samples out of 8642\n",
      "INFO: done 912 samples out of 8642\n",
      "INFO: done 928 samples out of 8642\n",
      "INFO: done 944 samples out of 8642\n",
      "INFO: done 960 samples out of 8642\n",
      "INFO: done 976 samples out of 8642\n",
      "INFO: done 992 samples out of 8642\n",
      "INFO: done 1008 samples out of 8642\n",
      "INFO: done 1024 samples out of 8642\n",
      "INFO: done 1040 samples out of 8642\n",
      "INFO: done 1056 samples out of 8642\n",
      "INFO: done 1072 samples out of 8642\n",
      "INFO: done 1088 samples out of 8642\n",
      "INFO: done 1104 samples out of 8642\n",
      "INFO: done 1120 samples out of 8642\n",
      "INFO: done 1136 samples out of 8642\n",
      "INFO: done 1152 samples out of 8642\n",
      "INFO: done 1168 samples out of 8642\n",
      "INFO: done 1184 samples out of 8642\n",
      "INFO: done 1200 samples out of 8642\n",
      "INFO: done 1216 samples out of 8642\n",
      "INFO: done 1232 samples out of 8642\n",
      "INFO: done 1248 samples out of 8642\n",
      "INFO: done 1264 samples out of 8642\n",
      "INFO: done 1280 samples out of 8642\n",
      "INFO: done 1296 samples out of 8642\n",
      "INFO: done 1312 samples out of 8642\n",
      "INFO: done 1328 samples out of 8642\n",
      "INFO: done 1344 samples out of 8642\n",
      "INFO: done 1360 samples out of 8642\n",
      "INFO: done 1376 samples out of 8642\n",
      "INFO: done 1392 samples out of 8642\n",
      "INFO: done 1408 samples out of 8642\n",
      "INFO: done 1424 samples out of 8642\n",
      "INFO: done 1440 samples out of 8642\n",
      "INFO: done 1456 samples out of 8642\n",
      "INFO: done 1472 samples out of 8642\n",
      "INFO: done 1488 samples out of 8642\n",
      "INFO: done 1504 samples out of 8642\n",
      "INFO: done 1520 samples out of 8642\n",
      "INFO: done 1536 samples out of 8642\n",
      "INFO: done 1552 samples out of 8642\n",
      "INFO: done 1568 samples out of 8642\n",
      "INFO: done 1584 samples out of 8642\n",
      "INFO: done 1600 samples out of 8642\n",
      "INFO: done 1616 samples out of 8642\n",
      "INFO: done 1632 samples out of 8642\n",
      "INFO: done 1648 samples out of 8642\n",
      "INFO: done 1664 samples out of 8642\n",
      "INFO: done 1680 samples out of 8642\n",
      "INFO: done 1696 samples out of 8642\n",
      "INFO: done 1712 samples out of 8642\n",
      "INFO: done 1728 samples out of 8642\n",
      "INFO: done 1744 samples out of 8642\n",
      "INFO: done 1760 samples out of 8642\n",
      "INFO: done 1776 samples out of 8642\n",
      "INFO: done 1792 samples out of 8642\n",
      "INFO: done 1808 samples out of 8642\n",
      "INFO: done 1824 samples out of 8642\n",
      "INFO: done 1840 samples out of 8642\n",
      "INFO: done 1856 samples out of 8642\n",
      "INFO: done 1872 samples out of 8642\n",
      "INFO: done 1888 samples out of 8642\n",
      "INFO: done 1904 samples out of 8642\n",
      "INFO: done 1920 samples out of 8642\n",
      "INFO: done 1936 samples out of 8642\n",
      "INFO: done 1952 samples out of 8642\n",
      "INFO: done 1968 samples out of 8642\n",
      "INFO: done 1984 samples out of 8642\n",
      "INFO: done 2000 samples out of 8642\n",
      "INFO: done 2016 samples out of 8642\n",
      "INFO: done 2032 samples out of 8642\n",
      "INFO: done 2048 samples out of 8642\n",
      "INFO: done 2064 samples out of 8642\n",
      "INFO: done 2080 samples out of 8642\n",
      "INFO: done 2096 samples out of 8642\n",
      "INFO: done 2112 samples out of 8642\n",
      "INFO: done 2128 samples out of 8642\n",
      "INFO: done 2144 samples out of 8642\n",
      "INFO: done 2160 samples out of 8642\n",
      "INFO: done 2176 samples out of 8642\n",
      "INFO: done 2192 samples out of 8642\n",
      "INFO: done 2208 samples out of 8642\n",
      "INFO: done 2224 samples out of 8642\n",
      "INFO: done 2240 samples out of 8642\n",
      "INFO: done 2256 samples out of 8642\n",
      "INFO: done 2272 samples out of 8642\n",
      "INFO: done 2288 samples out of 8642\n",
      "INFO: done 2304 samples out of 8642\n",
      "INFO: done 2320 samples out of 8642\n",
      "INFO: done 2336 samples out of 8642\n",
      "INFO: done 2352 samples out of 8642\n",
      "INFO: done 2368 samples out of 8642\n",
      "INFO: done 2384 samples out of 8642\n",
      "INFO: done 2400 samples out of 8642\n",
      "INFO: done 2416 samples out of 8642\n",
      "INFO: done 2432 samples out of 8642\n",
      "INFO: done 2448 samples out of 8642\n",
      "INFO: done 2464 samples out of 8642\n",
      "INFO: done 2480 samples out of 8642\n",
      "INFO: done 2496 samples out of 8642\n",
      "INFO: done 2512 samples out of 8642\n",
      "INFO: done 2528 samples out of 8642\n",
      "INFO: done 2544 samples out of 8642\n",
      "INFO: done 2560 samples out of 8642\n",
      "INFO: done 2576 samples out of 8642\n",
      "INFO: done 2592 samples out of 8642\n",
      "INFO: done 2608 samples out of 8642\n",
      "INFO: done 2624 samples out of 8642\n",
      "INFO: done 2640 samples out of 8642\n",
      "INFO: done 2656 samples out of 8642\n",
      "INFO: done 2672 samples out of 8642\n",
      "INFO: done 2688 samples out of 8642\n",
      "INFO: done 2704 samples out of 8642\n",
      "INFO: done 2720 samples out of 8642\n",
      "INFO: done 2736 samples out of 8642\n",
      "INFO: done 2752 samples out of 8642\n",
      "INFO: done 2768 samples out of 8642\n",
      "INFO: done 2784 samples out of 8642\n",
      "INFO: done 2800 samples out of 8642\n",
      "INFO: done 2816 samples out of 8642\n",
      "INFO: done 2832 samples out of 8642\n",
      "INFO: done 2848 samples out of 8642\n",
      "INFO: done 2864 samples out of 8642\n",
      "INFO: done 2880 samples out of 8642\n",
      "INFO: done 2896 samples out of 8642\n",
      "INFO: done 2912 samples out of 8642\n",
      "INFO: done 2928 samples out of 8642\n",
      "INFO: done 2944 samples out of 8642\n",
      "INFO: done 2960 samples out of 8642\n",
      "INFO: done 2976 samples out of 8642\n",
      "INFO: done 2992 samples out of 8642\n",
      "INFO: done 3008 samples out of 8642\n",
      "INFO: done 3024 samples out of 8642\n",
      "INFO: done 3040 samples out of 8642\n",
      "INFO: done 3056 samples out of 8642\n",
      "INFO: done 3072 samples out of 8642\n",
      "INFO: done 3088 samples out of 8642\n",
      "INFO: done 3104 samples out of 8642\n",
      "INFO: done 3120 samples out of 8642\n",
      "INFO: done 3136 samples out of 8642\n",
      "INFO: done 3152 samples out of 8642\n",
      "INFO: done 3168 samples out of 8642\n",
      "INFO: done 3184 samples out of 8642\n",
      "INFO: done 3200 samples out of 8642\n",
      "INFO: done 3216 samples out of 8642\n",
      "INFO: done 3232 samples out of 8642\n",
      "INFO: done 3248 samples out of 8642\n",
      "INFO: done 3264 samples out of 8642\n",
      "INFO: done 3280 samples out of 8642\n",
      "INFO: done 3296 samples out of 8642\n",
      "INFO: done 3312 samples out of 8642\n",
      "INFO: done 3328 samples out of 8642\n",
      "INFO: done 3344 samples out of 8642\n",
      "INFO: done 3360 samples out of 8642\n",
      "INFO: done 3376 samples out of 8642\n",
      "INFO: done 3392 samples out of 8642\n",
      "INFO: done 3408 samples out of 8642\n",
      "INFO: done 3424 samples out of 8642\n",
      "INFO: done 3440 samples out of 8642\n",
      "INFO: done 3456 samples out of 8642\n",
      "INFO: done 3472 samples out of 8642\n",
      "INFO: done 3488 samples out of 8642\n",
      "INFO: done 3504 samples out of 8642\n",
      "INFO: done 3520 samples out of 8642\n",
      "INFO: done 3536 samples out of 8642\n",
      "INFO: done 3552 samples out of 8642\n",
      "INFO: done 3568 samples out of 8642\n",
      "INFO: done 3584 samples out of 8642\n",
      "INFO: done 3600 samples out of 8642\n",
      "INFO: done 3616 samples out of 8642\n",
      "INFO: done 3632 samples out of 8642\n",
      "INFO: done 3648 samples out of 8642\n",
      "INFO: done 3664 samples out of 8642\n",
      "INFO: done 3680 samples out of 8642\n",
      "INFO: done 3696 samples out of 8642\n",
      "INFO: done 3712 samples out of 8642\n",
      "INFO: done 3728 samples out of 8642\n",
      "INFO: done 3744 samples out of 8642\n",
      "INFO: done 3760 samples out of 8642\n",
      "INFO: done 3776 samples out of 8642\n",
      "INFO: done 3792 samples out of 8642\n",
      "INFO: done 3808 samples out of 8642\n",
      "INFO: done 3824 samples out of 8642\n",
      "INFO: done 3840 samples out of 8642\n",
      "INFO: done 3856 samples out of 8642\n",
      "INFO: done 3872 samples out of 8642\n",
      "INFO: done 3888 samples out of 8642\n",
      "INFO: done 3904 samples out of 8642\n",
      "INFO: done 3920 samples out of 8642\n",
      "INFO: done 3936 samples out of 8642\n",
      "INFO: done 3952 samples out of 8642\n",
      "INFO: done 3968 samples out of 8642\n",
      "INFO: done 3984 samples out of 8642\n",
      "INFO: done 4000 samples out of 8642\n",
      "INFO: done 4016 samples out of 8642\n",
      "INFO: done 4032 samples out of 8642\n",
      "INFO: done 4048 samples out of 8642\n",
      "INFO: done 4064 samples out of 8642\n",
      "INFO: done 4080 samples out of 8642\n",
      "INFO: done 4096 samples out of 8642\n",
      "INFO: done 4112 samples out of 8642\n",
      "INFO: done 4128 samples out of 8642\n",
      "INFO: done 4144 samples out of 8642\n",
      "INFO: done 4160 samples out of 8642\n",
      "INFO: done 4176 samples out of 8642\n",
      "INFO: done 4192 samples out of 8642\n",
      "INFO: done 4208 samples out of 8642\n",
      "INFO: done 4224 samples out of 8642\n",
      "INFO: done 4240 samples out of 8642\n",
      "INFO: done 4256 samples out of 8642\n",
      "INFO: done 4272 samples out of 8642\n",
      "INFO: done 4288 samples out of 8642\n",
      "INFO: done 4304 samples out of 8642\n",
      "INFO: done 4320 samples out of 8642\n",
      "INFO: done 4336 samples out of 8642\n",
      "INFO: done 4352 samples out of 8642\n",
      "INFO: done 4368 samples out of 8642\n",
      "INFO: done 4384 samples out of 8642\n",
      "INFO: done 4400 samples out of 8642\n",
      "INFO: done 4416 samples out of 8642\n",
      "INFO: done 4432 samples out of 8642\n",
      "INFO: done 4448 samples out of 8642\n",
      "INFO: done 4464 samples out of 8642\n",
      "INFO: done 4480 samples out of 8642\n",
      "INFO: done 4496 samples out of 8642\n",
      "INFO: done 4512 samples out of 8642\n",
      "INFO: done 4528 samples out of 8642\n",
      "INFO: done 4544 samples out of 8642\n",
      "INFO: done 4560 samples out of 8642\n",
      "INFO: done 4576 samples out of 8642\n",
      "INFO: done 4592 samples out of 8642\n",
      "INFO: done 4608 samples out of 8642\n",
      "INFO: done 4624 samples out of 8642\n",
      "INFO: done 4640 samples out of 8642\n",
      "INFO: done 4656 samples out of 8642\n",
      "INFO: done 4672 samples out of 8642\n",
      "INFO: done 4688 samples out of 8642\n",
      "INFO: done 4704 samples out of 8642\n",
      "INFO: done 4720 samples out of 8642\n",
      "INFO: done 4736 samples out of 8642\n",
      "INFO: done 4752 samples out of 8642\n",
      "INFO: done 4768 samples out of 8642\n",
      "INFO: done 4784 samples out of 8642\n",
      "INFO: done 4800 samples out of 8642\n",
      "INFO: done 4816 samples out of 8642\n",
      "INFO: done 4832 samples out of 8642\n",
      "INFO: done 4848 samples out of 8642\n",
      "INFO: done 4864 samples out of 8642\n",
      "INFO: done 4880 samples out of 8642\n",
      "INFO: done 4896 samples out of 8642\n",
      "INFO: done 4912 samples out of 8642\n",
      "INFO: done 4928 samples out of 8642\n",
      "INFO: done 4944 samples out of 8642\n",
      "INFO: done 4960 samples out of 8642\n",
      "INFO: done 4976 samples out of 8642\n",
      "INFO: done 4992 samples out of 8642\n",
      "INFO: done 5008 samples out of 8642\n",
      "INFO: done 5024 samples out of 8642\n",
      "INFO: done 5040 samples out of 8642\n",
      "INFO: done 5056 samples out of 8642\n",
      "INFO: done 5072 samples out of 8642\n",
      "INFO: done 5088 samples out of 8642\n",
      "INFO: done 5104 samples out of 8642\n",
      "INFO: done 5120 samples out of 8642\n",
      "INFO: done 5136 samples out of 8642\n",
      "INFO: done 5152 samples out of 8642\n",
      "INFO: done 5168 samples out of 8642\n",
      "INFO: done 5184 samples out of 8642\n",
      "INFO: done 5200 samples out of 8642\n",
      "INFO: done 5216 samples out of 8642\n",
      "INFO: done 5232 samples out of 8642\n",
      "INFO: done 5248 samples out of 8642\n",
      "INFO: done 5264 samples out of 8642\n",
      "INFO: done 5280 samples out of 8642\n",
      "INFO: done 5296 samples out of 8642\n",
      "INFO: done 5312 samples out of 8642\n",
      "INFO: done 5328 samples out of 8642\n",
      "INFO: done 5344 samples out of 8642\n",
      "INFO: done 5360 samples out of 8642\n",
      "INFO: done 5376 samples out of 8642\n",
      "INFO: done 5392 samples out of 8642\n",
      "INFO: done 5408 samples out of 8642\n",
      "INFO: done 5424 samples out of 8642\n",
      "INFO: done 5440 samples out of 8642\n",
      "INFO: done 5456 samples out of 8642\n",
      "INFO: done 5472 samples out of 8642\n",
      "INFO: done 5488 samples out of 8642\n",
      "INFO: done 5504 samples out of 8642\n",
      "INFO: done 5520 samples out of 8642\n",
      "INFO: done 5536 samples out of 8642\n",
      "INFO: done 5552 samples out of 8642\n",
      "INFO: done 5568 samples out of 8642\n",
      "INFO: done 5584 samples out of 8642\n",
      "INFO: done 5600 samples out of 8642\n",
      "INFO: done 5616 samples out of 8642\n",
      "INFO: done 5632 samples out of 8642\n",
      "INFO: done 5648 samples out of 8642\n",
      "INFO: done 5664 samples out of 8642\n",
      "INFO: done 5680 samples out of 8642\n",
      "INFO: done 5696 samples out of 8642\n",
      "INFO: done 5712 samples out of 8642\n",
      "INFO: done 5728 samples out of 8642\n",
      "INFO: done 5744 samples out of 8642\n",
      "INFO: done 5760 samples out of 8642\n",
      "INFO: done 5776 samples out of 8642\n",
      "INFO: done 5792 samples out of 8642\n",
      "INFO: done 5808 samples out of 8642\n",
      "INFO: done 5824 samples out of 8642\n",
      "INFO: done 5840 samples out of 8642\n",
      "INFO: done 5856 samples out of 8642\n",
      "INFO: done 5872 samples out of 8642\n",
      "INFO: done 5888 samples out of 8642\n",
      "INFO: done 5904 samples out of 8642\n",
      "INFO: done 5920 samples out of 8642\n",
      "INFO: done 5936 samples out of 8642\n",
      "INFO: done 5952 samples out of 8642\n",
      "INFO: done 5968 samples out of 8642\n",
      "INFO: done 5984 samples out of 8642\n",
      "INFO: done 6000 samples out of 8642\n",
      "INFO: done 6016 samples out of 8642\n",
      "INFO: done 6032 samples out of 8642\n",
      "INFO: done 6048 samples out of 8642\n",
      "INFO: done 6064 samples out of 8642\n",
      "INFO: done 6080 samples out of 8642\n",
      "INFO: done 6096 samples out of 8642\n",
      "INFO: done 6112 samples out of 8642\n",
      "INFO: done 6128 samples out of 8642\n",
      "INFO: done 6144 samples out of 8642\n",
      "INFO: done 6160 samples out of 8642\n",
      "INFO: done 6176 samples out of 8642\n",
      "INFO: done 6192 samples out of 8642\n",
      "INFO: done 6208 samples out of 8642\n",
      "INFO: done 6224 samples out of 8642\n",
      "INFO: done 6240 samples out of 8642\n",
      "INFO: done 6256 samples out of 8642\n",
      "INFO: done 6272 samples out of 8642\n",
      "INFO: done 6288 samples out of 8642\n",
      "INFO: done 6304 samples out of 8642\n",
      "INFO: done 6320 samples out of 8642\n",
      "INFO: done 6336 samples out of 8642\n",
      "INFO: done 6352 samples out of 8642\n",
      "INFO: done 6368 samples out of 8642\n",
      "INFO: done 6384 samples out of 8642\n",
      "INFO: done 6400 samples out of 8642\n",
      "INFO: done 6416 samples out of 8642\n",
      "INFO: done 6432 samples out of 8642\n",
      "INFO: done 6448 samples out of 8642\n",
      "INFO: done 6464 samples out of 8642\n",
      "INFO: done 6480 samples out of 8642\n",
      "INFO: done 6496 samples out of 8642\n",
      "INFO: done 6512 samples out of 8642\n",
      "INFO: done 6528 samples out of 8642\n",
      "INFO: done 6544 samples out of 8642\n",
      "INFO: done 6560 samples out of 8642\n",
      "INFO: done 6576 samples out of 8642\n",
      "INFO: done 6592 samples out of 8642\n",
      "INFO: done 6608 samples out of 8642\n",
      "INFO: done 6624 samples out of 8642\n",
      "INFO: done 6640 samples out of 8642\n",
      "INFO: done 6656 samples out of 8642\n",
      "INFO: done 6672 samples out of 8642\n",
      "INFO: done 6688 samples out of 8642\n",
      "INFO: done 6704 samples out of 8642\n",
      "INFO: done 6720 samples out of 8642\n",
      "INFO: done 6736 samples out of 8642\n",
      "INFO: done 6752 samples out of 8642\n",
      "INFO: done 6768 samples out of 8642\n",
      "INFO: done 6784 samples out of 8642\n",
      "INFO: done 6800 samples out of 8642\n",
      "INFO: done 6816 samples out of 8642\n",
      "INFO: done 6832 samples out of 8642\n",
      "INFO: done 6848 samples out of 8642\n",
      "INFO: done 6864 samples out of 8642\n",
      "INFO: done 6880 samples out of 8642\n",
      "INFO: done 6896 samples out of 8642\n",
      "INFO: done 6912 samples out of 8642\n",
      "INFO: done 6928 samples out of 8642\n",
      "INFO: done 6944 samples out of 8642\n",
      "INFO: done 6960 samples out of 8642\n",
      "INFO: done 6976 samples out of 8642\n",
      "INFO: done 6992 samples out of 8642\n",
      "INFO: done 7008 samples out of 8642\n",
      "INFO: done 7024 samples out of 8642\n",
      "INFO: done 7040 samples out of 8642\n",
      "INFO: done 7056 samples out of 8642\n",
      "INFO: done 7072 samples out of 8642\n",
      "INFO: done 7088 samples out of 8642\n",
      "INFO: done 7104 samples out of 8642\n",
      "INFO: done 7120 samples out of 8642\n",
      "INFO: done 7136 samples out of 8642\n",
      "INFO: done 7152 samples out of 8642\n",
      "INFO: done 7168 samples out of 8642\n",
      "INFO: done 7184 samples out of 8642\n",
      "INFO: done 7200 samples out of 8642\n",
      "INFO: done 7216 samples out of 8642\n",
      "INFO: done 7232 samples out of 8642\n",
      "INFO: done 7248 samples out of 8642\n",
      "INFO: done 7264 samples out of 8642\n",
      "INFO: done 7280 samples out of 8642\n",
      "INFO: done 7296 samples out of 8642\n",
      "INFO: done 7312 samples out of 8642\n",
      "INFO: done 7328 samples out of 8642\n",
      "INFO: done 7344 samples out of 8642\n",
      "INFO: done 7360 samples out of 8642\n",
      "INFO: done 7376 samples out of 8642\n",
      "INFO: done 7392 samples out of 8642\n",
      "INFO: done 7408 samples out of 8642\n",
      "INFO: done 7424 samples out of 8642\n",
      "INFO: done 7440 samples out of 8642\n",
      "INFO: done 7456 samples out of 8642\n",
      "INFO: done 7472 samples out of 8642\n",
      "INFO: done 7488 samples out of 8642\n",
      "INFO: done 7504 samples out of 8642\n",
      "INFO: done 7520 samples out of 8642\n",
      "INFO: done 7536 samples out of 8642\n",
      "INFO: done 7552 samples out of 8642\n",
      "INFO: done 7568 samples out of 8642\n",
      "INFO: done 7584 samples out of 8642\n",
      "INFO: done 7600 samples out of 8642\n",
      "INFO: done 7616 samples out of 8642\n",
      "INFO: done 7632 samples out of 8642\n",
      "INFO: done 7648 samples out of 8642\n",
      "INFO: done 7664 samples out of 8642\n",
      "INFO: done 7680 samples out of 8642\n",
      "INFO: done 7696 samples out of 8642\n",
      "INFO: done 7712 samples out of 8642\n",
      "INFO: done 7728 samples out of 8642\n",
      "INFO: done 7744 samples out of 8642\n",
      "INFO: done 7760 samples out of 8642\n",
      "INFO: done 7776 samples out of 8642\n",
      "INFO: done 7792 samples out of 8642\n",
      "INFO: done 7808 samples out of 8642\n",
      "INFO: done 7824 samples out of 8642\n",
      "INFO: done 7840 samples out of 8642\n",
      "INFO: done 7856 samples out of 8642\n",
      "INFO: done 7872 samples out of 8642\n",
      "INFO: done 7888 samples out of 8642\n",
      "INFO: done 7904 samples out of 8642\n",
      "INFO: done 7920 samples out of 8642\n",
      "INFO: done 7936 samples out of 8642\n",
      "INFO: done 7952 samples out of 8642\n",
      "INFO: done 7968 samples out of 8642\n",
      "INFO: done 7984 samples out of 8642\n",
      "INFO: done 8000 samples out of 8642\n",
      "INFO: done 8016 samples out of 8642\n",
      "INFO: done 8032 samples out of 8642\n",
      "INFO: done 8048 samples out of 8642\n",
      "INFO: done 8064 samples out of 8642\n",
      "INFO: done 8080 samples out of 8642\n",
      "INFO: done 8096 samples out of 8642\n",
      "INFO: done 8112 samples out of 8642\n",
      "INFO: done 8128 samples out of 8642\n",
      "INFO: done 8144 samples out of 8642\n",
      "INFO: done 8160 samples out of 8642\n",
      "INFO: done 8176 samples out of 8642\n",
      "INFO: done 8192 samples out of 8642\n",
      "INFO: done 8208 samples out of 8642\n",
      "INFO: done 8224 samples out of 8642\n",
      "INFO: done 8240 samples out of 8642\n",
      "INFO: done 8256 samples out of 8642\n",
      "INFO: done 8272 samples out of 8642\n",
      "INFO: done 8288 samples out of 8642\n",
      "INFO: done 8304 samples out of 8642\n",
      "INFO: done 8320 samples out of 8642\n",
      "INFO: done 8336 samples out of 8642\n",
      "INFO: done 8352 samples out of 8642\n",
      "INFO: done 8368 samples out of 8642\n",
      "INFO: done 8384 samples out of 8642\n",
      "INFO: done 8400 samples out of 8642\n",
      "INFO: done 8416 samples out of 8642\n",
      "INFO: done 8432 samples out of 8642\n",
      "INFO: done 8448 samples out of 8642\n",
      "INFO: done 8464 samples out of 8642\n",
      "INFO: done 8480 samples out of 8642\n",
      "INFO: done 8496 samples out of 8642\n",
      "INFO: done 8512 samples out of 8642\n",
      "INFO: done 8528 samples out of 8642\n",
      "INFO: done 8544 samples out of 8642\n",
      "INFO: done 8560 samples out of 8642\n",
      "INFO: done 8576 samples out of 8642\n",
      "INFO: done 8592 samples out of 8642\n",
      "INFO: done 8608 samples out of 8642\n",
      "INFO: done 8624 samples out of 8642\n",
      "INFO: done 8640 samples out of 8642\n",
      "INFO: done 8642 samples out of 8642\n"
     ]
    }
   ],
   "source": [
    "# prediction over all samples\n",
    "nb_samples = len( valid_idx_pair_list )\n",
    "dmvn_scores = []\n",
    "for start_idx in range( 0, nb_samples, batch_size ) :\n",
    "    end_idx = min( nb_samples, start_idx + batch_size )\n",
    "    X = prepare_one_batch_input( sample_tensor_list, valid_idx_pair_list[ start_idx:end_idx ] )\n",
    "    pred_masks, pred_probs = dmvn_model.predict( X )\n",
    "    mask_perc = ( pred_masks > .5 ).mean( axis = (2,3) )\n",
    "    world_perc, probe_perc = mask_perc.T\n",
    "    det_score = pred_probs[:,1]\n",
    "    dmvn_scores.append( np.column_stack( [ probe_perc, world_perc, det_score ] ) )\n",
    "    # visualize samples if necessary\n",
    "    for this_donor, this_probe, this_masks, this_probs, this_file_pair in zip( X['world'], X['probe'], pred_masks, pred_probs, valid_image_pair_list[ start_idx:end_idx ] ) :\n",
    "        this_probe_id, this_donor_id = [ os.path.basename( f ).split('.')[0] for f in this_file_pair ]\n",
    "        this_output_file = os.path.join( visualization_dir, \"S-%.4f=P-%s_x_D-%s.jpg\" % ( this_probs[1], this_probe_id, this_donor_id ) )\n",
    "        _ = visualize_debug_dualmask( this_donor, this_probe, this_masks, this_probs,\n",
    "                                      output_file = this_output_file,\n",
    "                                      th = vis_mask_thresh,\n",
    "                                      visualization_level = visualization_level )\n",
    "    # print stats\n",
    "    print \"INFO: done\", end_idx, \"samples out of\", nb_samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Save prediction to output csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: successfully save all prediction scores into /nas/medifor/yue_wu/release/Deep-Matching-Validation-Network/expt/test_on_paired_casia/dmvn_on_paired_casia.csv\n"
     ]
    }
   ],
   "source": [
    "dmvn_scores = np.row_stack( dmvn_scores )\n",
    "# save prediction results\n",
    "output_lines = [ \",\".join( [ \"probe_file\", \"donor_file\", \"proba\" ] ) ]\n",
    "for this_image_pair, this_score in zip( valid_image_pair_list, dmvn_scores ) :\n",
    "    probe_file, donor_file = this_image_pair\n",
    "    donor_perc, probe_perc, proba = this_score\n",
    "    this_line = [ probe_file, donor_file ] + [ \"%.4f\" % proba ]\n",
    "    output_lines.append( \",\".join( this_line ) )\n",
    "\n",
    "with open( output_res_csv, 'w' ) as OUT :\n",
    "    OUT.write( \"\\n\".join( output_lines ) + \"\\n\" )\n",
    "\n",
    "print \"INFO: successfully save all prediction scores into\", output_res_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Performance evalution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: DMVN-loc on the paired CASIA dataset fscore = 0.81872909699\n",
      "INFO: DMVN-det on the paired CASIA dataset fscore = 0.858191831115\n",
      "INFO: DMVN-loc on the paired CASIA dataset auc = 0.902429489292\n",
      "INFO: DMVN-det on the paired CASIA dataset auc = 0.925318259198\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAHwCAYAAAB0TTiEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZmZjZw/gfTe9eXx71zUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f254d2450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lut = dict( zip( splicing_img_pair_list, label_list  ) )\n",
    "y_true = np.array( [ int( lut[ key ] ) for key in valid_image_pair_list ] )\n",
    "y_pred_loc = dmvn_scores[:,[0,1]].mean( axis = -1 )\n",
    "y_pred_det = dmvn_scores[:,2]\n",
    "# evaluate using fscore\n",
    "_ = evaluate_fscore( y_true, y_pred_loc > 0, 'DMVN-loc on the paired CASIA dataset')\n",
    "_ = evaluate_fscore( y_true, y_pred_det > .5, 'DMVN-det on the paired CASIA dataset')\n",
    "# evaluate using auc\n",
    "auc0 = evaluate_auc( y_true, y_pred_loc, 'DMVN-loc on the paired CASIA dataset' )\n",
    "auc1 = evaluate_auc( y_true, y_pred_det, 'DMVN-det on the paired CASIA dataset' )\n",
    "# prepare ROC curve\n",
    "fpr0, tpr0, _ = roc_curve ( y_true, y_pred_loc, 1 )\n",
    "fpr1, tpr1, _ = roc_curve ( y_true, y_pred_det, 1 )\n",
    "# prepare imposter v.s. genuine score distribution\n",
    "pos_idx = np.nonzero( y_true == 1 )[0].tolist()\n",
    "neg_idx = np.nonzero( y_true == 0 )[0].tolist()\n",
    "hist_x = np.linspace( 0, 1, 257 )\n",
    "imposter_cnt, _ = np.histogram( y_pred_det[ neg_idx ], hist_x )\n",
    "imposter_prob = imposter_cnt.astype( float ) / np.sum( imposter_cnt )\n",
    "genuine_cnt, _ = np.histogram( y_pred_det[ pos_idx ], hist_x )\n",
    "genuine_prob = genuine_cnt.astype( float ) / np.sum( genuine_cnt )\n",
    "# plot\n",
    "pyplot.figure( figsize=(16,8) )\n",
    "pyplot.subplot(121)\n",
    "pyplot.plot( fpr0, tpr0 )\n",
    "pyplot.plot( fpr1, tpr1, 'r' )\n",
    "pyplot.legend( [ 'DMVN-loc, AUC=%.2f%%' % ( auc0 * 100 ), 'DMVN-det, AUC=%.2f%%' % (auc1 * 100) ], loc = 4 )\n",
    "pyplot.xlabel( 'False Positive Rate' )\n",
    "pyplot.ylabel( 'True Positive Rate' )\n",
    "pyplot.title( 'ROC of DMVN on the paired CASIA dataset' )\n",
    "pyplot.subplot(122)\n",
    "pyplot.bar( hist_x[:-1], imposter_prob, alpha = 1, width = 1./256, color = 'b' )\n",
    "pyplot.bar( hist_x[:-1], genuine_prob, alpha = .5, width = 1./256, color = 'r' )\n",
    "pyplot.legend( [ 'imposter distribution', 'genuine distribution'], loc = 4 )\n",
    "pyplot.xlabel( 'DMVN Detected Splicing Probability' )\n",
    "pyplot.ylabel( 'Datat Percentage' )\n",
    "pyplot.title( 'Imposter v.s. Genuine Splicing Score Distribution' )\n",
    "pyplot.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
